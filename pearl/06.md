# 1. 
A: O(n^2) 은 n=10,000 에서 1년

B: O(nlogn) 은 n=10,000 에서 1일

컴퓨터 성능 1000배 증가

A 는 약 0.365일, B 는 약 0.001 일

A 는 0.4 * (a^2) = 1 a^2 = 2.74 a = 1.65 즉 n 16500개?

B 는 0.001 * (blogb) = 1 blogb = 1000 b는 약 140이래. n 은 1,400,000개?


# 2.
- 500자리 정수 인수분해
나눗셈성능 좋은 하드웨어 쓰자...
- 큰 텍스트파일 특정 문자열 검색
트라이, 인덱싱, 해시 쓰기?

# 3. 배정도 부동소수점을 단정도 부동소수점 타입으로 변경하면 2배 빨라짐

챗지피티의 힘을 빌림
```python
import numpy as np
import time

def benchmark_sum(data_type, size=10000000):
    data = np.arange(1, size+1, dtype=data_type)
    start = time.perf_counter()
    result = np.sum(data)
    end = time.perf_counter()

    # 실제 정수 합: 1 + 2 + ... + size = size*(size+1)/2
    actual = (size * (size + 1)) // 2

    return result, (end - start), abs(result - actual)

if __name__ == "__main__":
    # float64(배정도) 테스트
    float64_result, float64_time, float64_err = benchmark_sum(np.float64)
    print("float64 결과:", float64_result)
    print("float64 오차:", float64_err)
    print("float64 시간:", float64_time, "초")

    # float32(단정도) 테스트
    float32_result, float32_time, float32_err = benchmark_sum(np.float32)
    print("float32 결과:", float32_result)
    print("float32 오차:", float32_err)
    print("float32 시간:", float32_time, "초")

```
```
float64 결과: 50000005000000.0
float64 오차: 0.0
float64 시간: 0.0033595000000000014 초
float32 결과: 50000004000000.0
float32 오차: 0.0
float32 시간: 0.0017800000000000038 초
```
꽤나 두배차이남. 여기서 n 값 늘리면 더 차이심해지지만 오차가 커짐

지금보다 옛날은 메모리도 작고 캐시도 작고 부동소수점계산기도 안좋았으니 오차 아주작은 선에서 좋았을듯

# 4.

# 5.
성능향상과 비용은 지수함수이지 않을까

# 6.
취향차이로 생각. MVP 를 중요시하는 회사도 있음

다만, 너무 과한 MVP 는 개선을 실패하고 새로 만들어야 할수도 있지 않을까? 트레이드 오프를 따져가며 선택하자

# 7.
- 교통사고를 낸 차
  - 승용차
  - 이륜차
  - 엔진없는 것들(자전거, 킥보드, 인라인스케이트도 교통사곤가)
- 상해의 정도
  - 경상
  - 중상
  - 사망
- 교통사고 위치
  - 차도
  - 인도
      
 
