# 9. S3와 유사한 객체 저장소

## Amazon S3
- RESTFul 기반 인터페이스로 이용가능한 객체 저장소
```
gpt4o 요약
Amazon S3는 AWS의 확장 가능하고 안전하며 고가용성의 객체 스토리지 서비스로,
데이터를 인터넷에서 쉽게 저장하고 검색할 수 있습니다. 버킷과 객체로 구성되며,
높은 내구성, 가용성, 보안성을 제공하여 다양한 데이터 저장 및 관리 요구를 충족합니다.
```
## 저장소 시스템 101
### 저장소 종류
- 블록(Block) 저장소
- 파일(File) 저장소
- 객체(Object) 저장소

### 블록 저장소
- 원시 블록을 서버에 볼륨 형태로 제공
- 가장 유연하고, 융통성이 높은 저장소
- 물리적 연결(HDD, SSD), 네트워크 연결(FC, iSCSI) 모두 블록저장소

### 파일 저장소
- 블록 저장소 위에 구현됨
- 데이터는 계층적으로 구성되는 디렉터리 안에 보관됨
- 하나의 저장소를 여러 서버에 동시에 붙일 수 있다(파일 수준 네트워크 프로토콜 사용 시)

### 객체 저장소
- 데이터 영속성을 높이고 대규모 애플리케이션 지원하며 비용 낮추기 위해 의도적으로 성능을 희생
- cold 데이터 보관에 초점을 맞춤
- 모든 데이터를 수평적 구조 내에 객체로 보관
- 계층적 디렉터리 제공 X
- 데이터 접근은 RESTful API 사용
- 다른 저장소 유형에 비해 상대적으로 느림

### 객체 저장소 용어 정리

#### 버킷 (Bucket)
- Amazon S3에서 데이터를 저장하는 기본 단위.
- 고유한 이름을 가지며 전역적으로 유일, 데이터가 저장되는 물리적 위치(리전)를 정의.

#### 객체 (Object)
- S3에 저장되는 기본 데이터 단위.
- 데이터 자체와 메타데이터로 구성되며, 고유한 키로 식별.
- 메타데이터는 객체를 기술하는 이름-값 쌍의 집합

#### 버전 (Version)
- S3 버킷에서 객체의 변경 내역을 관리하는 방식.
- 버전 관리를 활성화하면 객체의 모든 버전을 저장하여 데이터 복구 및 변경 추적이 가능.

#### URI (Uniform Resource Identifier)
- S3의 객체를 식별하는 고유한 경로.
- `s3://bucket-name/key` 형식으로 나타내며, 객체에 접근하는 데 사용.
- key 는 Object Name

#### SLA (Service Level Agreement)
- 서비스 제공자가 보장하는 서비스 수준.
- Amazon S3 SLA: 99.99%의 가용성, 99.999999999%의 객체 내구성을 보장하며, 하나의 가용성 구역 전체가 소실되어도 데이터 복원 가능, 서비스 수준을 충족하지 못할 경우 보상 정책을 제공.

## 문제 이해 및 설계 범위 확정
### 기능 요구사항
- 버킷 생성
- 객체 업로드, 다운로드
- 객체 버전
- 버킷 내 객체 목록 출력 기능(aws s3 ls 와 유사해야함)
### 비기능 요구사항
- 매년 100PB 추가
- 식스나인(99.9999%) 수준 데이터 내구성
- 포나인(99.99%) 수준 서비스 가용성
- 저장소 효율성 : 높은 수준의 안정성, 성능 보증하되 저장소 비용은 최대한 낮추어야함

### 대략적인 규모 추정
- 디스크 용량 : 일반적인 분포를 따를 때 6.8억개 객체, 0.68TB 정도의 메타데이터 저장 공간(메타데이터는 1객체당 1KB 정도라 가정)
- IOPS : HDD, SATA 인터페이스 기준 100~150 IOPS (S3 Glacier 가 장기 아카이빙을 위한 스토리지로, 주로 HDD 사용한다고 함)

## 개략적 설계안 제시 및 동의 구하기
### 객체저장소의 흥미로운 속성
#### 객체 불변성
- 객체 저장소에 보관되는 객체들은 변경이 불가능함
- 객체 저장소와 다른 두 저장소 유형의 가장 큰 차이
- 삭제 후 새 버전 객체로 대체할 순 있어도, 점진적 변경은 불가
#### 키-값 저장소
- 키: URI, 값: 객체 데이터
#### 저장은 1회, 읽기는 여러 번
- 쓰기는 1회, 읽기는 여러번 발생
- 링크드인 조사 결과에 따르면, 객체 저장소 요청의 95%는 읽기 요청
#### 소형, 대형 객체 동시 지원
- 다양한 크기의 객체를 문제 없이 저장할 수 있다

### 설계 철학이 UNIX 파일 시스템과 유사
- 메타데이터 : 아이노드
- 데이터 저장소 : 하드디스크
- 차이점
  - 메타데이터에는 데이터저장소에 보관된 객체를 요청하는데 필요한 식별자(ID)가 보관됨
  - 아이노드에는 파일 블록 포인터 목록이 저장됨
### 개략적 설계안
 ![KakaoTalk_Photo_2024-05-20-13-46-41](https://github.com/wjddusgh/jpa-study/assets/69251780/2f1f3f05-9dbb-4773-8494-9846c4058b65)

#### 로드 밸런서
RESTful API 요청을 서버들에 분산
#### API 서비스
여러 서비스에 대한 호출을 조율하는 역할, 무상태 서비스이므로 수평적 규모 확장 가능
#### IAM 서비스
인증, 권한 부여, 접근 제어 처리
#### 데이터, 메타데이터 저장소
- 각각 실제 데이터, 메타데이터를 보관하는 저장소
- 실제 데이터 관련 연산은 객체 ID(UUID) 통해서 이루어짐
- 두 저장소는 논리적 구분일 뿐, 구현 방식은 여러가지 있을 수 있음

### 객체 업로드
1. HTTP PUT 요청으로 버킷 생성
2. IAM 호출하여 버킷 WRITE 권한 확인
3. 버킷 메타데이터 생성(메타데이터 저장소)
4. HTTP PUP 요청으로 script.txt 객체 생성
5. IAM 호출하여 객체 WRITE 권한 확인
6. 객체 업로드
7. 객체의 메타데이터 등록(object_name, object_id, bucket_id)

### 객체 다운로드
- 계층 구조는 없지만, 버킷이름, 객체이름 연결하면 논리적으로 흉내낼 수 있음(ex. /bucket_name/script.txt)
1. HTTP GET 요청으로 객체 요청
2. IAM 호출하여 버킷 READ 권한 확인(버킷 내 객체별로도 ACL 가질 수 있다함)
3. 권한 있으면 api 서비스가 해당 객체 uuid 를 메타데이터 저장소에서 가져옴
4. uuid 로 객체 저장소에서 데이터 가져옴
5. HTTP 응답으로 데이터 반환

## 상세 설계

### 데이터 저장소
![KakaoTalk_Photo_2024-05-20-15-01-34](https://github.com/wjddusgh/jpa-study/assets/69251780/eea0e5e1-3f03-4d39-9654-fa32268d5f0a)

#### 데이터 라우팅 서비스
- 데이터 노드 클러스터에 접근하기 위한 RESTful 또는 gRPC 서비스 제공
- 무상태 서비스
- 역할
  - 배치 서비스를 호출하여 데이터를 저장할 최적의 데이터 노드 판단
  - 데이터 노드에서 데이터를 읽어 API 서비스에 반환
  - 데이터 노드에 데이터 기록
#### 배치 서비스
- 어느 데이터 노드에 데이터를 저장할지 결정하는 역할
- 내부적으로 가상 클러스터 지도 유지, 클러스터의 물리적 형상 정보가 보관됨
- 가상 클러스터 지도 이용하여 데이터 사본이 물리적으로 다른 위치에 놓이도록 함(높은 데이터 내구성 유지하는 핵심 요소)
- 모든 데이터 노드와 지속적으로 박동 메시지를 주고받으며 상태를 모니터링(15초 동안 응답 안한 노드는 지도에 죽은(down) 노드로 표시)
- 아주 중요한 서비스이므로 5~7 노드를 갖는 배치 서비스 클러스터를 합의 프로토콜 사용해 구축할 것 권장
- 합의 프로토콜
  - 분산 시스템에서 여러 노드가 동일한 결정을 내릴 수 있도록 하는 메커니즘
  - 분산 환경에서 데이터의 일관성과 무결성을 보장하는 데 필수적
  - 일부 노드에 장애가 생겨도 건강한 노드 수가 클러스터 크기의 절반 이상이면 서비스 지속할 수 있도록 보장
#### 데이터 노드
- 실제 객체 데이터가 보관되는 곳
- 여러 노드에 데이터를 복제함으로써 다중화그룹 을 통해 데이터 안정성, 내구성 보증
- 배치 서비스에 주기적으로 박동 메시지 보내는 서비스 데몬 존재
- 박동 메시지
  - 해당 데이터 노드에 부착된 디스크 드라이브의 수
  - 각 드라이브에 저장된 데이터의 양
- 배치 서비스가 못보던 데이터노드에서 박동 메시지 받으면, 해당 노드에 ID 부여 후 가상 클러스터 지도에 추가, 아래 정보 반환
  - 해당 데이터노드에 부여한 고유 식별자
  - 가상 클러스터 지도
  - 데이터 사본을 보관할 위치
#### 데이터 저장 흐름
1. API 서비스가 객체 데이터를 데이터 저장소로 포워딩
2. 데이터 라우팅 서비스가 해당 객체에 UUID 할당, 배치 서비스에 해당 객체 보관할 주 데이터 노드 반환 요청
3. 데이터 라우팅 서비스가 저장할 데이터를 UUID 와 함께 주 데이터 노드에 직접 전송
4. 주 데이터 노드는 데이터를 자기 노드에 지역적으로 저장하는 한편, 두 개의 부 데이터 노드에 다중화함. 다중화까지 성공하면 데이터 라우팅 서비스에 응답 보냄
5. 객체의 UUID, 즉 객체 ID 를 API 서비스에 반환

- 배치 서비스에서 데이터 노드 조회 연산 구현에는 보통 안정 해시를 사용함
- 데이터 노드 다중화의 경우 응답을 보내는 경우를 나눌 수 있다
  - n 개의 부 데이터 노드 저장 완료 응답을 0~n 개 받을 경우 데이터 저장 완료 응답 보내기
  - n 개 받을 경우 : 데이터 일관성 측면에서는 최선이지만, 응답 지연은 가장 높다
  - 나머지 : 갯수에 따라 데이터 일관성<> 응답 지연간 trade off, 결과적 일관성 형태

### 데이터는 어떻게 저장되는가
#### 각각의 객체를 개별 파일로 저장
- 가장 단순한 방안
- 작은 파일이 많아지면 문제가 생김
  - 낭비되는 데이터 블록 수가 늘어남
  - 시스템의 아이노드 용량 한계 초과 문제(아이노드 사용 갯수는 디스크가 초기화되는 순간에 결정됨)
- WAL(객체 저장할 때 이미 존재하는 파일에 추가) 또는 읽기전용 파일로 변경으로 어느정도 해결은 가능함
- 읽기-쓰기 파일에서는 쓰기 연산이 순차적으로 이루어져야 함 -> 이 때문에 쓰기 대역폭이 심각하게 줄어듦
### 객체 소재 확인
- 각각의 데이터파일 안에 많은 작은 객체가 있다면 uuid로 이를 어떻게 구분할까?
- 필요한 정보
  - 객체가 보관된 데이터 파일
  - 데이터 파일 내 객체 오프셋
  - 객체 크기
- 이러한 정보가 저장되는 테이블 필요
  - 한번 쓰기 후엔 변경이 안되며, 읽기가 빈번하므로 RDBMS 채택
  - 한 데이터노드당 하나의 RDBMS 설치하면 좋음(데이터노드마다 이걸 공유할 필요가 없으니)

### 데이터 내구성
#### 하드웨어 장애와 장애 도메인
- 종류와 상관없이 하드 디스크 장애는 피할 수 없다
- 내구성 높이는 검증된 방법은, 데이터를 여러 대의 하드 드라이브에 복사하여 어떤 드라이브에서 발생한 장애가 전체 데이터 가용성에 영향 안주도록 하는것
- HDD 연간 장애율이 0.81% 라면, 데이터 3중 복제시 내구성은 1 - (0.0081)^3 = ~0.999999 로 대략적으로 요구사항 맞출 수 있음
#### 소거 코드
- 데이터를 일정 크기의 단위로 분할하고, 같은 크기의 패리티 데이터를 생성하여 저장
- 데이터를 8조각으로 분할, 4개의 패리티 생성 시 12조각 데이터 분할 저장 -> 소거 코드 이용 시 최대 4개 노드에 장애가 동시에 발생하더라도 원본 데이터 복원 가능
- 보통 **리드-솔로몬 코드**를 사용한다고 함
- 장점
  - RAID 나 3중 복제같은 것 보다 공간효율이 뛰어남(3중복제는 200% 더필요한데, 소거 코드는 50% 더 필요)
  - 소거코드는 보다 높은 데이터 내구성을 달성할 수 있음
- 단점
  - 데이터를 읽으려면 데이터를 나눈 갯수만큼 가져와야 해서 계산, 읽기/쓰기 의 응답 지연이 높아짐     

 #### 정확성 검증
 - 대규모 시스템의 경우 디스크 뿐 아니라 메모리 데이터 훼손 문제도 발생함
 - 메모리 훼손 문제는 프로세스 경계에 데이터 검증 체크섬을 두어 해결 가능(체크섬이 같으면 아주 높은 확률로 데이터 온전, 아닐수도 있지만 확률이 너무 낮다고 함)
 - 알고리즘 종류 : MD5, SHA1, HMAC 등

### 메타데이터 데이터 모델
#### 지원해야하는 질의
1. 객체 이름으로 객체 ID 찾기
2. 객체 이름에 기반하여 객체 삽입/삭제
3. 같은 접두어를 갖는 버킷 내의 모든 객체 목록 확인

#### 버킷 테이블 규모 확장
- 버킷 테이블은 그리 크지 않아 한 DB에도 가능하지만, 모든 읽기 요청 처리에는 cpu 나 네트워크 대역폭이 부족할 수 있어, 사본을 만들어 분산한다
#### 객체 테이블 규모 확장
- 버킷 id 기준 샤딩 : 핫스팟 샤드 때문에 문제됨
- 객체 id 기준 샤딩 : 부하는 균등해지지만, 질의 1과 2를 효율적으로 지원 못함
- 두 id 결합하여 샤딩에 이용

### 버킷 내 객체 목록 확인
- s3는 수평적 계층이지만, 디렉터리 계층 흉내를 위한 질의 가능
- 접두어를 주고 질의하면 찾은 파일에서 접두어 이외의 / 가 나오면 잘라서 출력

### 객체 버전
- 버전 기능이 없을 경우, 이미 버킷에 존재하는 객체와 같은 이름으로 삽입을 한다면 이전 객체의 메타데이터는 완전히 사라져 복구 불가
- 메타데이터 저장소에서 버전 정보 저장
  - 기존 메타데이터 대체 대신에, 버킷 id, 객체 이름은 그대로 사용하며 TIMEUUID 를 이용한 객체id로 메타데이터 추가
  - 버킷 id, 객체 이름이 같은 메타데이터가 여러개 있다면, 객체 id가 가장 최신인 것을 반환
  - 객체 삭제 시 해당 객체의 모든 버전을 버킷 안에 그대로 둔 채, 삭제 표식만 추가함

 ### 큰 파일의 업로드 성능 최적화
 #### 멀티파트 업로드
 1. 클라이언트가 멀티파트 업로드를 시작하기 위해 객체 저장소 호출
 2. 해당 업로드의 유일한 식별 uploadID 반환
 3. 파일을 작은 객체로 분할 후 업로드 시작, 각 파트는 2단계에서 받은 ETag와 함께 올림
 4. 조각 하나 업로드 될 때마다 데이터 저장소는 ETag 반환, ETag는 기본적으로 해당 조강에 대한 MD5 해시 체크섬으로, 정상 업로드 검사에 이용
 5. 모든 조각 업로드 끝나면 멀티파트 업로드 종료 요청(uploadID, 조각 번호 목록, ETag 목록 반환)
 6. 데이터 저장소는 원본 객체 복원, 성공 시 클라이언트에 성공메시지 반환
- 추가적으로 멀티파트 업로드 완료 시 조각 데이터는 삭제하는게 용량 확보에 좋음

### 쓰레기 수집
#### 쓰레기 데이터 종류
- 객체의 지연된 삭제
- 갈 곳 없는 데이터 : 불완전히 업로드된 데이터, 또는 취소된 멀티파트 업로드 데이터
- 훼손된 데이터 : 체크섬 검사에 실패한 데이터
